# Pre-Pretraining
Pre-pretraining LLaMA-2 using custom domain datasets (Cricket, Education, Medical) with LoRA adapters and 4-bit quantization.
